{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweeness centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweeness Centrality T_cells and B_Cells\n",
    "Betweenness centrality of a node 𝑣 is the sum of the fraction of all-pairs shortest paths that pass through 𝑣\n",
    "\n",
    "$c_{B}(v)=\\sum_{s, t \\in V} \\frac{\\sigma(s, t \\mid v)}{\\sigma(s, t)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Intersection(lst1, lst2):\n",
    "#    return set(lst1).intersection(lst2)\n",
    "\n",
    "#subgraphs = [cell_graph.subgraph(c).copy() for c in components]\n",
    "#n =len(subgraphs)\n",
    "#largest_component = subgraphs[n-1]\n",
    "#nodes_in_largest = largest_component.nodes()\n",
    "#t_b_nk_cells = list(nodes[nodes['phenotype'].apply(lambda phenotype: phenotype in ['T'])].cell_id.values)\n",
    "#tumor_cells = list(nodes[nodes['phenotype'].apply(lambda phenotype: phenotype in ['tumor'])].cell_id.values)\n",
    "\n",
    "#t_b_nk_cells = Intersection(nodes_in_largest,t_b_nk_cells)\n",
    "#tumor_cells = Intersection(nodes_in_largest,tumor_cells)\n",
    "\n",
    "#bc = nx.betweenness_centrality_subset(largest_component, t_b_nk_cells ,tumor_cells)\n",
    "#cell_bc_df = pd.DataFrame(bc.items(),columns=['cell_id','betweeness_centrality'])\n",
    "\n",
    "#len(cell_bc_df)\n",
    "\n",
    "#cell_bc_df.describe()\n",
    "\n",
    "#nodes = nodes.merge(cell_bc_df, on ='cell_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on component features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './data/output/'\n",
    "output_directory = os.listdir(directory)\n",
    "feature_inspection = pd.DataFrame({})\n",
    "select_features = ['component','AUC_area']\n",
    "\n",
    "for folder in output_directory[:]:\n",
    "    if folder.startswith('DEEPMEL'):\n",
    "        name = folder.split('_')[1]\n",
    "        component_features = pd.read_csv(directory + folder +'/component_features.csv')\n",
    "        component_features = component_features[select_features]\n",
    "        component_features_pivotted = pd.pivot_table(component_features, values = select_features[1], columns = select_features[0])\n",
    "        component_features_pivotted.columns.name = None\n",
    "        component_features_pivotted = component_features_pivotted.reset_index()\n",
    "        component_features_pivotted = component_features_pivotted.drop(['index'], axis =1)\n",
    "        m = len(component_features_pivotted.columns)\n",
    "        columns = component_features_pivotted.columns\n",
    "        new_names = ['component_'+str(i) for i in range(m)]\n",
    "        renaming ={}\n",
    "        for old_name, new_name in zip(columns,new_names):\n",
    "            renaming[old_name] = new_name\n",
    "        \n",
    "        component_features_pivotted = component_features_pivotted.rename(columns = renaming)    \n",
    "\n",
    "        component_features_pivotted['name'] = name\n",
    "        \n",
    "        feature_inspection = pd.concat([feature_inspection,component_features_pivotted])\n",
    "        \n",
    "        feature_inspection = feature_inspection.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_inspection['component_600'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(feature_inspection)\n",
    "for column in feature_inspection.columns:\n",
    "    if (feature_inspection[column].value_counts()[0])/n > 0.92 :\n",
    "        feature_inspection = feature_inspection.drop([column], axis=1 )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_inspection.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_inspection['label'] = feature_inspection.name.apply(lambda x: labeling(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 10)\n",
    "label = feature_inspection.label.values\n",
    "features_scaled= feature_inspection.drop(['name','label'],axis=1)\n",
    "principalComponents = pca.fit_transform(features_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['pc1', 'pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10'])\n",
    "principalDf['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(principalDf, hue='label', corner =True).savefig(PLOT_DIRECTORY+select_features[1]+'_PCA.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_nodes = principalDf.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(correlation_nodes.iloc[:,10:],annot=True)\n",
    "plt.savefig(PLOT_DIRECTORY + select_features[1]+'_correlation_label.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = principalDf.label.values\n",
    "nodes_columns = principalDf.columns[:]\n",
    "spearmanr_corr ={}\n",
    "\n",
    "\n",
    "for column in nodes_columns:\n",
    "    if column != 'name' :\n",
    "        column_value = principalDf[column].values\n",
    "        spearmanr_corr[column] = scipy.stats.spearmanr(column_value, label).correlation\n",
    "\n",
    "    \n",
    "spearmanr_corr = pd.DataFrame(spearmanr_corr, index = [0])\n",
    "spearmanr_corr = pd.melt(spearmanr_corr).set_index(['variable'])\n",
    "f, ax = plt.subplots(figsize=(10, 20))\n",
    "ax = sns.heatmap(spearmanr_corr,annot=True)\n",
    "plt.savefig(PLOT_DIRECTORY + select_features[1]+'_spearman_rho.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = principalDf.label.values\n",
    "laplace_columns_ = principalDf.columns[:]\n",
    "kendall_corr ={}\n",
    "for column in laplace_columns_:\n",
    "    if column != 'name' :\n",
    "        column_value = principalDf[column].values\n",
    "        kendall_corr[column] = scipy.stats.kendalltau(column_value, label).correlation\n",
    "\n",
    "kendall_corr = pd.DataFrame(kendall_corr, index = [0])\n",
    "kendall_corr = pd.melt(kendall_corr).set_index(['variable'])\n",
    "f, ax = plt.subplots(figsize=(10, 20))\n",
    "ax = sns.heatmap(kendall_corr,annot=True)\n",
    "plt.savefig(PLOT_DIRECTORY +  select_features[1]+'_kendall_tau.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
